{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook is almost completely derived from Susan Li's https://towardsdatascience.com/building-a-logistic-regression-in-python-step-by-step-becd4d56c9c8 ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt \n",
    "plt.rc(\"font\", size=14)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from IPython.display import display, HTML\n",
    "sns.set(style=\"white\")\n",
    "sns.set(style=\"whitegrid\", color_codes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data\n",
    "\n",
    "~~The data is related with direct marketing campaigns (phone calls) of a Portuguese banking institution. The classification goal is to predict if the client will subscribe (1/0) a term deposit (variable y).~~\n",
    "\n",
    "~~This dataset provides the customer information. It includes 41188 records and 21 fields.~~\n",
    "\n",
    "We'll use the NSCH_2016_topical dataset instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullDF = pd.read_csv('/home/welling/git/synecoace/data/nsch_2016_topical.csv')\n",
    "print fullDF.columns\n",
    "subDF=fullDF[fullDF.FIPSST == 45][['ACE3', 'ACE4', 'ACE5', 'ACE6', 'ACE7',\n",
    "                                   'ACE8', 'ACE9', 'ACE10',\n",
    "                                   'FWC', 'YEAR', 'FPL', 'SC_AGE_YEARS',\n",
    "                                   'K4Q30_R', 'K4Q32X01',\n",
    "                                   'K7Q30', 'K7Q31', 'AGEPOS4',\n",
    "                                   'HHLANGUAGE', # 1=English 2=Spanish 3=Other\n",
    "                                   'SC_CSHCN', # selected child special health care needs (1=yes, 2=no)\n",
    "                                   'SC_RACE_R', # selected child race (1=white, 2=black, 3=native 4=asian 5=islands, 6=other, 7=mixed)\n",
    "                                   'SC_HISPANIC_R', # 1=latinx, 2=not\n",
    "                                   'TOTCSHCN', # Total children with special health care needs\n",
    "                                   'TOTNONSHCN', # Total children\n",
    "                                   'K2Q05', # Born 3 weeks before due date (1=yes, 2=no)\n",
    "                                   'BIRTHWT_VL', # Birth weight very low (1=yes, 2=no)\n",
    "                                   'BIRTHWT_L', # Birth weight low (1=yes, 2=no)\n",
    "                                   'MOMAGE', # Age of mother at birth (scalar)\n",
    "                                   'S4Q01' # Doctor visit in last 12 months (1=yes, 2=no)\n",
    "                                  ]]\n",
    "\n",
    "data = subDF\n",
    "\n",
    "print(data.shape)\n",
    "\n",
    "#data = pd.read_csv('banking.csv', header=0)\n",
    "data = data.dropna()\n",
    "print(data.shape)\n",
    "print(list(data.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input variables ##\n",
    "* SC_AGE_YEARS: selected child age (numeric) -> 'AGE'\n",
    "* K4Q30_R: Dental care 1=YES 2=YES,other(not dentist) 3=NO -> 'DENTALCARE'\n",
    "* K4Q32X01: vision tested by eye doctor (2.0 -> False) -> 'VISIONCARE'\n",
    "* K7Q30: sports teams 1=YES 2=NO -> 'SPORTSTEAMS'\n",
    "* K7Q31: clubs or organizations 1=YES 2=NO -> 'CLUBS'\n",
    "* FPL: percent of federal poverty level? (numeric, open-ended)\n",
    "* AGEPOS4: birth order (numeric) -> 'BIRTHORDER'\n",
    "* FWC: sample weight\n",
    "* ~~YEAR: survey year~~ drop this one since 2016 seems to be the only value for these samples\n",
    "* HHLANGUAGE: household language. Split into ENGLISH (val=1), SPANISH(val=2).  OTHER (val=3) false for both\n",
    "* SC_CSHCN: special health care needs 1=yes.  Convert to boolean\n",
    "* SC_RACE_R and SC_HISPANIC_R: convert to SC_RACE_WHITE, SC_RACE_BLACK, SC_RACE_HISPANIC, SC_RACE_NATIVE, SC_RACE_ASIAN, SC_RACE_ISLANDS, SC_RACE_OTHER, SC_RACE_MIXED (all boolean)\n",
    "* TOTCSHCN: TOTCSHCN (scalar)\n",
    "* TOTNONSHCN: convert to TOTKIDS by adding TOTCSHCN (scalar)\n",
    "* K2Q05: -> PREMATURE (1=yes)\n",
    "* BIRTHWT_VL -> boolean (1=yes)\n",
    "* BIRTHWT_L -> boolean (1=yes)\n",
    "* MOMAGE -> MOMAGE (scalar)\n",
    "* S4Q01 -> DOCTORVISIT (1=yes)\n",
    "\n",
    "## Predict Variable ##\n",
    "* ACE3: Parent Divorced -> PARENTDIVORCED\n",
    "* ACE4: Parent or guardian died -> PARENTDIED\n",
    "* ACE5: Parent or guardian spent time in jail -> PARENTJAIL\n",
    "* ACE6: Adult slap/kick/punch others -> SEEPUNCH\n",
    "* ACE7: experienced violence 1=YES 2=NO -> VIOLENCE\n",
    "* ACE8: family member mentally ill -> MENTALILL\n",
    "* ACE9: drugs and alcohol 1=YES 2=NO -> DRUGSALCOHOL\n",
    "* ACE10: treated unfairly because of race -> RACISM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['YEAR'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['YEAR'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.rename(columns={'AGEPOS4':'BIRTHORDER', 'SC_AGE_YEARS':'AGE', 'K4Q30_R':'DENTALCARE',\n",
    "                           'K4Q32X01':'VISIONCARE', 'K7Q30':'SPORTSTEAMS', 'K7Q31':'CLUBS',\n",
    "                            'ACE3':'PARENTDIVORCED',\n",
    "                            'ACE4':'PARENTDIED', 'ACE5':'PARENTJAIL', 'ACE6':'SEEPUNCH',\n",
    "                           'ACE7':'VIOLENCE', 'ACE8': 'MENTALILL', 'ACE9':'DRUGSALCOHOL',\n",
    "                           'ACE10':'RACISM'})\n",
    "acesL = ['PARENTDIVORCED', 'PARENTDIED', 'PARENTJAIL', 'SEEPUNCH', 'VIOLENCE', 'MENTALILL',\n",
    "         'DRUGSALCOHOL', 'RACISM']\n",
    "acesL.sort()\n",
    "boolColL = ['DENTALCARE', 'VISIONCARE', 'SPORTSTEAMS', 'CLUBS', 'HHLANGUAGE_ENGLISH', 'HHLANGUAGE_SPANISH',\n",
    "           'SC_RACE_WHITE', 'SC_RACE_BLACK', 'SC_RACE_HISPANIC', 'SC_RACE_NATIVE', 'SC_RACE_ASIAN',\n",
    "           'SC_RACE_ISLANDS', 'SC_RACE_OTHER', 'SC_RACE_MIXED', 'PREMATURE', 'BIRTHWT_VL', 'BIRTHWT_L',\n",
    "            'DOCTORVISIT']\n",
    "boolColL.sort()\n",
    "scalarColL = ['FPL', 'BIRTHORDER', 'AGE', 'TOTCSHCN', 'TOTKIDS', 'MOMAGE']\n",
    "scalarColL.sort()\n",
    "\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['AGE'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['BIRTHORDER'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pd.cut(data['FPL'], 8, labels=False)\n",
    "data['FPL_quantized'] = out\n",
    "data['FPL_quantized'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TOTCSHCN: convert to boolean CHSHCN\n",
    "TOTCSHCN plus TOTNONSHCN: convert to HHNCHILDREN (scalar)\n",
    "\n",
    "                                   'TOTCSHCN', # Total children with special health care needs\n",
    "                                   'TOTNONSHCN', # Total children without special health care needs\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "massaged_data = data[['FWC', 'AGE', 'FPL_quantized']].copy().rename(columns={'FPL_quantized':'FPL'})\n",
    "massaged_data['DENTALCARE'] = (data['DENTALCARE'] != 3.0)\n",
    "massaged_data['VISIONCARE'] = (data['VISIONCARE'] == 1.0)\n",
    "massaged_data['SPORTSTEAMS'] = (data['SPORTSTEAMS'] == 1.0)\n",
    "massaged_data['CLUBS'] = (data['CLUBS'] == 1.0)\n",
    "massaged_data['BIRTHORDER'] = data['BIRTHORDER']\n",
    "massaged_data['SC_CSHCN'] = (data['SC_CSHCN'] == 1.0)\n",
    "massaged_data['BIRTHWT_VL'] = (data['BIRTHWT_VL'] == 1.0)\n",
    "massaged_data['BIRTHWT_L'] = (data['BIRTHWT_L'] == 1.0)\n",
    "massaged_data['HHLANGUAGE_ENGLISH'] = (data['HHLANGUAGE'] == 1.0)\n",
    "massaged_data['HHLANGUAGE_SPANISH'] = (data['HHLANGUAGE'] == 2.0)\n",
    "massaged_data['DOCTORVISIT'] = (data['S4Q01'] == 1.0)\n",
    "massaged_data['PREMATURE'] = (data['K2Q05'] == 1.0)\n",
    "massaged_data['SC_RACE_WHITE'] = (data['SC_RACE_R'] == 1.0)\n",
    "massaged_data['SC_RACE_BLACK'] = (data['SC_RACE_R'] == 2.0)\n",
    "massaged_data['SC_RACE_NATIVE'] = (data['SC_RACE_R'] == 3.0)\n",
    "massaged_data['SC_RACE_ASIAN'] = (data['SC_RACE_R'] == 4.0)\n",
    "massaged_data['SC_RACE_ISLANDS'] = (data['SC_RACE_R'] == 5.0)\n",
    "massaged_data['SC_RACE_OTHER'] = (data['SC_RACE_R'] == 6.0)\n",
    "massaged_data['SC_RACE_MIXED'] = (data['SC_RACE_R'] == 7.0)\n",
    "massaged_data['SC_RACE_HISPANIC'] = (data['SC_HISPANIC_R'] == 1.0)\n",
    "massaged_data['TOTKIDS'] = data['TOTCSHCN'] + data['TOTCSHCN'] # scalar\n",
    "massaged_data['TOTCSHCN'] = data['TOTCSHCN']  # scalar\n",
    "massaged_data['MOMAGE'] = data['MOMAGE'] # scalar\n",
    "\n",
    "\n",
    "for ace in acesL:\n",
    "    massaged_data[ace] = (data[ace] == 1)\n",
    "massaged_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'What weighted fraction of samples have each ACE?'\n",
    "for col in acesL:\n",
    "    display(massaged_data[[col,'FWC']].groupby([col]).sum()/massaged_data['FWC'].sum())\n",
    "#massaged_data['VIOLENCE'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our classes are imbalanced, with many more subjects without ACEs than with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wtThisRow(row, colNm):\n",
    "    newRow = (row * row['FWC']).drop(['FWC', colNm])\n",
    "    newRow[colNm] = row[colNm]\n",
    "    newRow['FWC'] = row['FWC']\n",
    "    return newRow\n",
    "\n",
    "def unwtThisRow(row):\n",
    "    newRow = row / row['FWC']\n",
    "    return newRow\n",
    "\n",
    "def weightedMean(df, col):\n",
    "    meanDF = df.apply(wtThisRow, axis=1, colNm=col).groupby(col).mean()\n",
    "    return meanDF.apply(unwtThisRow, axis=1).drop('FWC', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'Weighted means by ACE status'\n",
    "for col in acesL:\n",
    "    display(weightedMean(massaged_data, col))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "\n",
    "Higher age is associated with higher ACEs, as expected. Higher income is associated with fewer ACEs.\n",
    "\n",
    "We can calculate categorical means for other categorical variables such as education and marital status to get a more detailed sense of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in scalarColL + boolColL:\n",
    "    display(weightedMean(massaged_data, col))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "for col in scalarColL:\n",
    "    for ace in acesL:\n",
    "        pd.crosstab(massaged_data[col],massaged_data[ace], values=massaged_data.FWC, aggfunc='sum').plot(kind='bar')\n",
    "        plt.xlabel(col)\n",
    "        plt.ylabel(ace)\n",
    "        plt.title('%s by %s' % (ace, col))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in boolColL:\n",
    "    for ace in acesL:\n",
    "        table=pd.crosstab(massaged_data[col],massaged_data[ace], values=massaged_data.FWC, aggfunc='sum')\n",
    "        table.div(table.sum(1).astype(float), axis=0).plot(kind='bar', stacked=True)\n",
    "        plt.xlabel(col)\n",
    "        plt.ylabel(ace)\n",
    "        plt.title('%s fractions by presence of %s' % (ace, col))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in scalarColL:\n",
    "    massaged_data[col].hist(weights=data.FWC)\n",
    "    plt.title('Histogram of %s' % col)\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkSamps(df, nSamp):\n",
    "    fracWt = df['FWC']/df['FWC'].sum()\n",
    "    choices = np.random.choice(len(df), nSamp, p=fracWt)\n",
    "    return df.iloc[choices].drop(columns=['FWC'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = massaged_data.copy()\n",
    "cat_vars = scalarColL\n",
    "for var in cat_vars:\n",
    "    cat_list = pd.get_dummies(data[var], prefix=var)\n",
    "    data1=data.join(cat_list)\n",
    "    data=data1\n",
    "\n",
    "#display(data.head())\n",
    "    \n",
    "cat_vars = scalarColL\n",
    "#print 'cat_vars: ', cat_vars\n",
    "data_vars = data.columns.values.tolist()\n",
    "#print 'data_vars: ', data_vars\n",
    "to_keep=[i for i in data_vars if i not in cat_vars]\n",
    "#print 'to_keep: ', to_keep\n",
    "data_final=data[to_keep]\n",
    "data_final.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How shall we handle the FPL, which represents a continuous variable? ###\n",
    "\n",
    "* binned : regress on FPL_0, FPL_1, etc.\n",
    "* ascending: regress on FPL_AT_LEAST_1, FPL_AT_LEAST_2, etc.\n",
    "* descending: regress on FPL_LESS_THAN_7, FPL_LESS_THAN_6, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FPL_MODE = 'descending'  # one of 'binned', 'ascending', 'descending'\n",
    "\n",
    "display(data_final.head())\n",
    "if FPL_MODE == 'binned':\n",
    "    assert 'FPL_0' in data_final.columns , 'data_final needs to be regenerated'\n",
    "elif FPL_MODE == 'ascending':\n",
    "    data_final1 = data_final.copy()\n",
    "    data_final1['FPL_AT_LEAST_7'] = data_final['FPL_7']\n",
    "    data_final1['FPL_AT_LEAST_6'] = data_final1['FPL_AT_LEAST_7'] | data_final['FPL_6']\n",
    "    data_final1['FPL_AT_LEAST_5'] = data_final1['FPL_AT_LEAST_6'] | data_final['FPL_5']\n",
    "    data_final1['FPL_AT_LEAST_4'] = data_final1['FPL_AT_LEAST_5'] | data_final['FPL_4']\n",
    "    data_final1['FPL_AT_LEAST_3'] = data_final1['FPL_AT_LEAST_4'] | data_final['FPL_3']\n",
    "    data_final1['FPL_AT_LEAST_2'] = data_final1['FPL_AT_LEAST_3'] | data_final['FPL_2']\n",
    "    data_final1['FPL_AT_LEAST_1'] = data_final1['FPL_AT_LEAST_2'] | data_final['FPL_1']\n",
    "    drop_these = ['FPL_0', 'FPL_1', 'FPL_2', 'FPL_3', 'FPL_4', 'FPL_5', 'FPL_6', 'FPL_7']\n",
    "    data_final1 = data_final1.drop(columns=drop_these)\n",
    "    data_final = data_final1\n",
    "elif FPL_MODE == 'descending':\n",
    "    data_final1 = data_final.copy()\n",
    "    data_final1['FPL_LESS_THAN_1'] = data_final['FPL_0']\n",
    "    data_final1['FPL_LESS_THAN_2'] = data_final1['FPL_LESS_THAN_1'] | data_final['FPL_1']\n",
    "    data_final1['FPL_LESS_THAN_3'] = data_final1['FPL_LESS_THAN_2'] | data_final['FPL_2']\n",
    "    data_final1['FPL_LESS_THAN_4'] = data_final1['FPL_LESS_THAN_3'] | data_final['FPL_3']\n",
    "    data_final1['FPL_LESS_THAN_5'] = data_final1['FPL_LESS_THAN_4'] | data_final['FPL_4']\n",
    "    data_final1['FPL_LESS_THAN_6'] = data_final1['FPL_LESS_THAN_5'] | data_final['FPL_5']\n",
    "    data_final1['FPL_LESS_THAN_7'] = data_final1['FPL_LESS_THAN_6'] | data_final['FPL_6']\n",
    "    drop_these = ['FPL_0', 'FPL_1', 'FPL_2', 'FPL_3', 'FPL_4', 'FPL_5', 'FPL_6', 'FPL_7']\n",
    "    data_final1 = data_final1.drop(columns=drop_these)\n",
    "    data_final = data_final1\n",
    "else:\n",
    "    raise RuntimeError('Unknown FPL_mode')\n",
    "display(data_final.head())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deal with weights by creating a new dataset by weighted sampling ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_resampled = mkSamps(data_final, 100000)\n",
    "data_resampled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Over-sampling using SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print [(col in acesL) for col in data_resampled.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = data_resampled.loc[:, [(col not in acesL) for col in data_resampled.columns]]\n",
    "X.head()\n",
    "y = {}\n",
    "for ace in acesL:\n",
    "    y[ace] = data_resampled.loc[:, [(col == ace) for col in data_resampled.columns]]\n",
    "for ace, yy in y.items():\n",
    "    print 'y[%s]: ' % ace\n",
    "    display(y[ace].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "os = SMOTE(random_state=0)\n",
    "X_train = {}\n",
    "X_test = {}\n",
    "y_train = {}\n",
    "y_test = {}\n",
    "os_data_X = {}\n",
    "os_data_y = {}\n",
    "for ace in acesL:\n",
    "    X_train[ace], X_test[ace], y_train[ace], y_test[ace] = train_test_split(X, y[ace], test_size=0.3, random_state=0)\n",
    "    columns = X_train[ace].columns\n",
    "\n",
    "    os_data_X[ace],os_data_y[ace]=os.fit_sample(X_train[ace], y_train[ace])\n",
    "    os_data_X[ace] = pd.DataFrame(data=os_data_X[ace],columns=columns )\n",
    "    os_data_y[ace]= pd.DataFrame(data=os_data_y[ace],columns=[ace])\n",
    "\n",
    "    # we can Check the numbers of our data\n",
    "    print(\"--------\")\n",
    "    print(\"Sampling for %s\" % ace)\n",
    "    print(\"length of oversampled data is \",len(os_data_X[ace]))\n",
    "    print(\"Number of no subscription in oversampled data\",len(os_data_y[ace][os_data_y[ace][ace]==0]))\n",
    "    print(\"Number of subscription\",len(os_data_y[ace][os_data_y[ace][ace]==1]))\n",
    "    print(\"Proportion of no subscription data in oversampled data is \",(float(len(os_data_y[ace][os_data_y[ace][ace]==0]))\n",
    "                                                                        /float(len(os_data_X[ace]))))\n",
    "    print(\"Proportion of subscription data in oversampled data is \",(float(len(os_data_y[ace][os_data_y[ace][ace]==1]))\n",
    "                                                                        /float(len(os_data_X[ace]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive feature elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_resampled_vars=data_resampled.columns.values.tolist()\n",
    "X=[i for i in data_resampled_vars if i not in acesL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "rfe = {}\n",
    "cols_after_rfe = {}\n",
    "for ace in acesL:\n",
    "    logreg = LogisticRegression()\n",
    "\n",
    "\n",
    "    rfe[ace] = RFE(logreg, 20)\n",
    "    rfe[ace] = rfe[ace].fit(os_data_X[ace], os_data_y[ace].values.ravel())\n",
    "    print '---------'\n",
    "    print 'Regressing for %s' % ace\n",
    "    print '---------'\n",
    "    print(rfe[ace].support_)\n",
    "    print(rfe[ace].ranking_)\n",
    "    cols_after_rfe[ace] = os_data_X[ace].columns[rfe[ace].support_]\n",
    "    print 'selected columns: ', cols_after_rfe[ace]\n",
    "    display(os_data_X[ace][cols_after_rfe[ace]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### find and remove columns that are poor regressors ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "cols_after_logit_fit = {}\n",
    "\n",
    "for ace in acesL:\n",
    "    X = os_data_X[ace][cols_after_rfe[ace]]\n",
    "    y = os_data_y[ace][ace]\n",
    "    logit_model=sm.Logit(y,X)\n",
    "    result=logit_model.fit(method='lbfgs')\n",
    "    print '------------'\n",
    "    print 'Fitting for %s' % ace\n",
    "    print '------------'\n",
    "    print(result.summary2())\n",
    "    cols_after_logit_fit[ace] = [k for k in cols_after_rfe[ace] if result.pvalues[k] < 0.1]\n",
    "    print 'retaining columns: ', cols_after_logit_fit[ace]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repeat regression with the good columns ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for ace in acesL:\n",
    "\n",
    "    X = os_data_X[ace][cols_after_logit_fit[ace]]\n",
    "    y = os_data_y[ace][ace]\n",
    "    logit_model=sm.Logit(y,X)\n",
    "    result=logit_model.fit(method='lbfgs')\n",
    "    print '------------'\n",
    "    print 'Fitting for %s' % ace\n",
    "    print '------------'\n",
    "    print(result.summary2())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "for ace in acesL:\n",
    "\n",
    "    X = os_data_X[ace][cols_after_logit_fit[ace]]\n",
    "    y = os_data_y[ace][ace]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "    logreg = LogisticRegression()\n",
    "    print '---------'\n",
    "    print 'fitting %s' % ace\n",
    "    print '---------'\n",
    "    display(logreg.fit(X_train, y_train))\n",
    "    y_pred = logreg.predict(X_test)\n",
    "    print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))\n",
    "    c_mtx = confusion_matrix(y_test, y_pred)\n",
    "    print 'confusion matrix: '\n",
    "    print(c_mtx)\n",
    "    print 'classification report: '\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.metrics import roc_auc_score\n",
    "#from sklearn.metrics import roc_curve\n",
    "#logit_roc_auc = roc_auc_score(y_test, logreg.predict(X_test))\n",
    "#fpr, tpr, thresholds = roc_curve(y_test, logreg.predict_proba(X_test)[:,1])\n",
    "#plt.figure()\n",
    "#plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "#plt.plot([0, 1], [0, 1],'r--')\n",
    "#plt.xlim([0.0, 1.0])\n",
    "#plt.ylim([0.0, 1.05])\n",
    "#plt.xlabel('False Positive Rate')\n",
    "#plt.ylabel('True Positive Rate')\n",
    "#plt.title('Receiver operating characteristic')\n",
    "#plt.legend(loc=\"lower right\")\n",
    "#plt.savefig('Log_ROC')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python2 (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
