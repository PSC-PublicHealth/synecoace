{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fullDF = pd.read_csv('/home/welling/git/synecoace/data/nsch_2016_topical.csv')\n",
    "print fullDF.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Model ##\n",
    "\n",
    "Consider two sequential ages, say 6 and 7 years.  Given an child at one age, the goal is to produce a *guide function* which can be used to select a collection of children at the other age which as a group describe the most likely match to the original child.  Specifically, given a sample of individuals at one age, the guide function should generate samples at the other age having the highest possible *mutual information* with the first group.\n",
    "\n",
    "The guided samples will be selected by applying *Metropolis sampling* using the guide function.  This requires only that the guide function be positive definite and integrable.  In essense the guide function is proportional to the likelihood that a sampled child at one age matches a specific child at the other age.\n",
    "\n",
    "We will develop an appropriate guide function by defining a function of an appropriate form in terms of a set of weights.  Samples will be drawn based on the given weights, the mutual information will be calculated, and the weights will be updated so as to increase the mutual information.  This process will be repeated until the mutual information is maximized.  The set of weights which produces the maximum mutual information is the optimal choice of weights given the initial choice of form for the guide function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factors we are using ##\n",
    "* ACE7: experienced violence\n",
    "* ACE8: drugs and alcohol\n",
    "* SC_AGE_YEARS: selected child age\n",
    "* K4Q32X01: vision tested by eye doctor (2.0 -> False)\n",
    "* K7Q30: sports teams\n",
    "* K7Q31: clubs or organizations\n",
    "* FPL: percent of federal poverty level?\n",
    "* AGEPOS4: birth order\n",
    "* FWC: sample weight\n",
    "* YEAR: survey year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subDF=fullDF[['ACE7', 'ACE8', 'FWC', 'YEAR', 'FPL', 'SC_AGE_YEARS','K4Q32X01', 'K7Q30', 'K7Q31', 'AGEPOS4']]\n",
    "subDF = subDF.dropna()\n",
    "print len(subDF)\n",
    "#print subDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "age6DF = subDF[subDF.SC_AGE_YEARS==6]\n",
    "print len(age6DF)\n",
    "age7DF = subDF[subDF.SC_AGE_YEARS==7]\n",
    "print len(age7DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select samples from the table in a weighted fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mkSamps(df, nSamp):\n",
    "    fracWt = df['FWC']/df['FWC'].sum()\n",
    "    choices = np.random.choice(len(df), nSamp, p=fracWt)\n",
    "    return df.iloc[choices].drop(columns=['FWC'])\n",
    "nSamp = 10\n",
    "print mkSamps(age6DF, nSamp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "COLUMN_DICT = {key : idx for idx, key in enumerate(mkSamps(subDF, 1).columns)}\n",
    "print COLUMN_DICT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FPL needs to be binned to form a histogram to get the quantization we need for this.  Bins of 50 seems OK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fplSamps = mkSamps(subDF, 100000)['FPL']\n",
    "plt.hist(fplSamps, bins=100)\n",
    "plt.title('Histogram of FPL values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to enumerate the possible states for our variables.  Assume fixed age and ignore the ACE components for the moment.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def whichBin(sampV):\n",
    "    \"\"\"\n",
    "    Input is an ndarray of sample values\n",
    "    \"\"\"\n",
    "    fplBinWidth = 50\n",
    "    fplMin = 50\n",
    "    bin = np.abs((sampV[:, COLUMN_DICT['FPL']] - fplMin) // 50).astype('int')\n",
    "    assert (bin >= 0).all() and (bin < 8).all(), 'FPL out of range?'\n",
    "    nBins = 8\n",
    "    # Each of the following is either 1.0 or 2.0\n",
    "    bin = 2 * bin + (sampV[:, COLUMN_DICT['K4Q32X01']] == 1.0)\n",
    "    nBins *= 2\n",
    "    bin = 2 * bin + (sampV[:, COLUMN_DICT['K7Q30']] == 1.0)\n",
    "    nBins *= 2\n",
    "    bin = 2 * bin + (sampV[:, COLUMN_DICT['K7Q31']] == 1.0)\n",
    "    nBins *= 2\n",
    "    return bin, nBins\n",
    "\n",
    "def scatter(idx, vals, target):\n",
    "    \"\"\"target[idx] += vals, but allowing for repeats in idx\"\"\"\n",
    "    np.add.at(target, idx.ravel(), vals.ravel())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def toHisto(sampV):\n",
    "    \"\"\"Generate a histogram of sample bins\"\"\"\n",
    "    binV, nBins = whichBin(sampV)\n",
    "    targ = np.zeros([nBins], dtype=np.int32)\n",
    "    vals = np.ones([len(sampV)], dtype=np.int32)\n",
    "    scatter(binV, vals, targ)\n",
    "    return targ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def toProbV(sampV):\n",
    "    sampH = toHisto(sampV)\n",
    "    probV = sampH.astype(np.float64)\n",
    "    probV /= np.sum(probV)\n",
    "    return probV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sampV = mkSamps(subDF, 1000)\n",
    "print sampV.columns\n",
    "print COLUMN_DICT['FPL']\n",
    "sampH = toHisto(sampV.values)\n",
    "print sampH\n",
    "probV = toProbV(sampV.values)\n",
    "print probV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the probV we can calculate mutual information:\n",
    "$$\n",
    "I(X;Y) = \\sum_{y \\in Y} \\sum_{x \\in X} p(x, y) log \\left (\\frac{p(x,y)}{p(x)p(y)} \\right )\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mutualInfo(sampVX, sampVY):\n",
    "    assert len(sampVX) == len(sampVY), 'Sample vector lengths do not match'\n",
    "    binVX, nBinsX = whichBin(sampVX)\n",
    "    binVY, nBinsY = whichBin(sampVY)\n",
    "    assert nBinsX == nBinsY, 'Unexpectedly got different bin counts?'\n",
    "    cA = np.zeros([nBinsX, nBinsX], dtype=np.int32)\n",
    "    idxV = np.ravel_multi_index(np.array([binVX, binVY]), (nBinsX, nBinsX))\n",
    "    np.add.at(cA.ravel(), idxV, np.ones(len(idxV), dtype=np.int32).ravel())\n",
    "    pA = cA.astype(np.float32)\n",
    "    pA /= sum(pA.ravel())\n",
    "    xPV = toProbV(sampVX)\n",
    "    yPV = toProbV(sampVY)\n",
    "    xyPA = np.einsum('i,j->ij', xPV, yPV)  # einsum is my new favorite function\n",
    "    oldErr = np.seterr(invalid='ignore', divide='ignore')\n",
    "    prodA = pA * np.nan_to_num(np.log(pA / xyPA))  # element-wise calculation\n",
    "    np.seterr(**oldErr)\n",
    "    return np.sum(prodA.ravel())\n",
    "\n",
    "sampX = mkSamps(subDF, 30000)\n",
    "sampY = mkSamps(subDF, 30000)\n",
    "print mutualInfo(sampX.values, sampY.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a scalar function on a pair of samples and a weight vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wtSer = pd.Series({'YEAR': 1.0,\n",
    "                   'FPL':1.0e-4,  # because it's percent\n",
    "                   'SC_AGE_YEARS': 1.0, \n",
    "                   'K4Q01': 1.0, \n",
    "                   'K4Q32X01': 1.0,\n",
    "                   'K7Q30':1.0,\n",
    "                   'K7Q31': 1.0,\n",
    "                   'AGEPOS4': 1.0}, index=subDF.columns)\n",
    "wtSer = wtSer.drop(labels=['ACE7', 'ACE8', 'FWC'])  # get the right index order but no extra entries\n",
    "print wtSer\n",
    "print wtSer.values\n",
    "print wtSer.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def funV(samps1V, samps2V, wtSerV):\n",
    "    \"\"\"\n",
    "    Returns a numpy vector the columns of which correspond to the input samples\n",
    "    \"\"\"\n",
    "    wtA = wtSerV\n",
    "    #print wtA.shape\n",
    "    #print samps1V.shape\n",
    "    offset = samps1V.shape[1] - wtSerV.shape[0]\n",
    "    #print offset\n",
    "    samp1A = samps1V[:, offset:]\n",
    "    samp2A = samps2V[:, offset:]\n",
    "    delta = samp1A - samp2A\n",
    "    print 'delta', delta\n",
    "    delta *= delta\n",
    "    print 'delta^2', delta\n",
    "    return np.exp(-np.asmatrix(wtA) * np.asmatrix(delta).transpose())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def lnLik(samps1V, samps2V, wtSerV):\n",
    "    \"\"\"\n",
    "    funV has the right shape to fill the role of likelihood in the Metropolis algorithm.  We'll\n",
    "    take the log, and use it as a log likelihood.\n",
    "    \"\"\"\n",
    "    wtA = wtSerV\n",
    "    offset = samps1V.shape[1] - wtSer.shape[0]\n",
    "    samp1A = samps1V[:, offset:]\n",
    "    samp2A = samps2V[:, offset:]\n",
    "    delta = samp1A - samp2A\n",
    "    delta *= delta\n",
    "    return np.asarray((-np.asmatrix(wtA) * np.asmatrix(delta).transpose())).reshape((-1, 1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print funV(mkSamps(subDF, 3).values, mkSamps(subDF, 3).values, wtSer)\n",
    "llk = lnLik(mkSamps(subDF, 3).values, mkSamps(subDF, 3).values, wtSer)\n",
    "print llk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now we need a mutator\n",
    "def mutate(sampV, df, stepSzV):\n",
    "    \"\"\"\n",
    "    Return a 'mutated' version of sampV, based on the given step sizes.  Unfortunately our samples\n",
    "    are discrete and come from a table, so I'm not sure how to do this unless we first generate\n",
    "    a proximity network of some sort, so for the moment let's just generate a new set of samples-\n",
    "    this corresponds to an infinitely wide mutator.\n",
    "    \"\"\"\n",
    "    return mkSamps(df, len(sampV)).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# And now we can write the Metropolis code.\n",
    "# Thanks to https://python4mpia.github.io/fitting_data/Metropolis-Hastings.html\n",
    "# initial guess for alpha as array.\n",
    "\n",
    "nSamp = 100\n",
    "testSamps = mkSamps(age6DF, nSamp)\n",
    "guess = mkSamps(age7DF, nSamp)\n",
    "# Prepare storing MCMC chain as array of arrays.\n",
    "A = [guess.values]\n",
    "# define stepsize of MCMC.\n",
    "stepsizes = np.empty([nSamp])\n",
    "stepsizes.fill(0.005)\n",
    "nIter = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Metropolis-Hastings with nIter iterations.\n",
    "accepted  = np.zeros([nSamp, 1], dtype=np.int)\n",
    "onesV = np.ones([nSamp], dtype=np.int).reshape((-1, 1))\n",
    "zerosV = np.zeros([nSamp], dtype=np.int).reshape((-1, 1))\n",
    "for n in range(nIter):\n",
    "    oldAlpha  = A[-1]  # old parameter value as array\n",
    "    oldLnLik = lnLik(testSamps.values, oldAlpha, wtSer)\n",
    "    newAlpha = mutate(oldAlpha, age7DF, stepsizes)\n",
    "    newLnLik = lnLik(testSamps.values, newAlpha, wtSer)\n",
    "    if (n % 100 == 0):\n",
    "        print '%s: %s' % (n, mutualInfo(testSamps.values, newAlpha))\n",
    "    choices = np.logical_or(newLnLik > oldLnLik,\n",
    "                            np.random.random(newLnLik.shape) < np.exp(newLnLik - oldLnLik))\n",
    "    rslt = np.choose(choices, [oldAlpha, newAlpha])\n",
    "    A.append(rslt)\n",
    "    accepted += np.choose(choices, [zerosV, onesV])\n",
    "\n",
    "plt.hist(accepted)\n",
    "acceptanceRate = accepted/float(nIter)\n",
    "plt.show()\n",
    "plt.hist(acceptanceRate)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nKeep = accepted.min()/10  # 10 mutations between samples to avoid correlation\n",
    "keepStep = nIter//nKeep\n",
    "burnIn = 10 * keepStep\n",
    "print nKeep, keepStep, burnIn\n",
    "assert burnIn < nIter, 'Not enough iterations for burn-in'\n",
    "clean = []\n",
    "for idx, sV in enumerate(A[burnIn:]):\n",
    "    if idx % keepStep == 0:\n",
    "        clean.append(sV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cleanV = np.concatenate(clean)\n",
    "print cleanV[-4:-1,...]\n",
    "print cleanV.shape\n",
    "print age7DF.columns\n",
    "print testSamps.values[-1, ...]\n",
    "print len(testSamps)\n",
    "print len(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "expandedTestV = np.repeat(testSamps.values, len(clean), axis=0)\n",
    "print mutualInfo(expandedTestV, cleanV)\n",
    "print mutualInfo(expandedTestV, mkSamps(age7DF, cleanV.shape[0]).values)\n",
    "print mutualInfo(expandedTestV, expandedTestV)\n",
    "print mutualInfo(cleanV, cleanV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ignore the rest of this ##\n",
    "These bits are just left-overs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ignore the rest of this ##\n",
    "These bits are just left-overs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wtDF = pd.DataFrame({'FPL':[1.0, 1.0], 'SC_AGE_YEARS': [1.0, 1.0], 'K4Q01': [1.0, 1.0], 'K4Q32X01': [1.0, 1.0],\n",
    "       'K7Q30':[1.0, 1.0], 'K7Q31': [1.0, 1.0], 'AGEPOS4': [1.0, 1.0]}, index=['ACE7', 'ACE8'])\n",
    "print wtDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def funV(samps1, samps2, wtDF):\n",
    "    \"\"\"\n",
    "    Returns a numpy matrix the rows of which correspond to ACE7 and ACE8 and\n",
    "    the columns of which correspond to the input samples\n",
    "    \"\"\"\n",
    "    wtA = wtDF.values\n",
    "    offset = samps1.values.shape[1] - wtDF.values.shape[1]\n",
    "    samp1A = samps1.values[:, offset:]\n",
    "    samp2A = samps2.values[:, offset:]\n",
    "    delta = samp1A - samp2A\n",
    "    return np.asmatrix(wtA) * np.asmatrix(delta).transpose()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print funV(mkSamps(subDF, 3), mkSamps(subDF, 3), wtDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "$\\mathcal L(\\{M_1,M_2,\\ldots,M_N\\};\\alpha) = \\prod_{n=1}^N p(M_n|\\alpha) = \\prod_{n=1}^N c\\left(\\frac{M_n}{M_\\odot}\\right)^{-\\alpha}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python2 (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
